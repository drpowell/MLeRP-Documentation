{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch and Dask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some basics on using creating a Dask cluster. MLeRP uses SLURM as a resource manager which Dask is able to tap into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-530a98e9-a8d5-11ed-ba1f-fa163e16ef68</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://192.168.0.213:8787/status\" target=\"_blank\">http://192.168.0.213:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">57d6a3b9</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://192.168.0.213:8787/status\" target=\"_blank\">http://192.168.0.213:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-eff00862-7c1c-41db-b8a8-4e9009df6232</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://192.168.0.213:36235\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://192.168.0.213:8787/status\" target=\"_blank\">http://192.168.0.213:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.0.213:36235' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster\n",
    "from dask import delayed\n",
    "import dask\n",
    "\n",
    "# Point Dask to the SLURM to use as it's back end\n",
    "cluster = SLURMCluster(\n",
    "    memory=\"64g\", processes=1, cores=8\n",
    ")\n",
    "\n",
    "# Scale out to 4 nodes\n",
    "num_nodes = 4\n",
    "cluster.scale(num_nodes)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask will spin our jobs up in anticipation for work to the scale that you specify\n",
    "\n",
    "You can check in on your jobs like you would with any other SLURM job with `squeue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "              1394     batch dask-wor mhar0048 PD       0:00      1 (None)\n",
      "              1393     batch dask-wor mhar0048 PD       0:00      1 (None)\n",
      "              1392     batch dask-wor mhar0048 PD       0:00      1 (None)\n",
      "              1391     batch dask-wor mhar0048 PD       0:00      1 (None)\n",
      "              1390     batch Jupyter  mhar0048  R    1:08:50      1 mlerp-node05\n",
      "              1373     batch Jupyter      bpal  R    2:08:33      1 mlerp-node05\n"
     ]
    }
   ],
   "source": [
    "!squeue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x7f464e0fac50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The adapt method will let us scale out as we need the compute\n",
    "# ...and scale back when we're idle letting others use the cluster\n",
    "cluster.adapt(minimum=0, maximum=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "              1390     batch Jupyter  mhar0048  R    1:08:51      1 mlerp-node05\n",
      "              1391     batch dask-wor mhar0048  R       0:01      1 mlerp-node05\n",
      "              1392     batch dask-wor mhar0048  R       0:01      1 mlerp-node09\n",
      "              1393     batch dask-wor mhar0048  R       0:01      1 mlerp-node09\n",
      "              1394     batch dask-wor mhar0048  R       0:01      1 mlerp-node09\n",
      "              1373     batch Jupyter      bpal  R    2:08:34      1 mlerp-node05\n"
     ]
    }
   ],
   "source": [
    "# You may need to run this cell a few times while waiting for Dask to clean up\n",
    "!squeue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has a lovely UI that will let you see how the tasks are being computed.\n",
    "You won't be able to connect to this with your web browser but VSCode has an extension for you to connect to it. \n",
    "\n",
    "Use the loopback address: http://127.0.0.1:8787 (Adjust the port if needed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a dask array and perform some computation. Dask arrays are parallelised across your workers nodes so they can be greater than the size of one worker's memory. Dask evaluates lazily, retuning 'futures' which record the tasks needed to be completed in the compute graph. They can be computed later for its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.45 GiB </td>\n",
       "                        <td> 119.21 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1000, 1000, 1000) </td>\n",
       "                        <td> (250, 250, 250) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 64 Tasks </td>\n",
       "                        <td> 64 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"250\" height=\"240\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"30\" x2=\"80\" y2=\"100\" />\n",
       "  <line x1=\"10\" y1=\"60\" x2=\"80\" y2=\"130\" />\n",
       "  <line x1=\"10\" y1=\"90\" x2=\"80\" y2=\"160\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"137\" />\n",
       "  <line x1=\"45\" y1=\"35\" x2=\"45\" y2=\"155\" />\n",
       "  <line x1=\"62\" y1=\"52\" x2=\"62\" y2=\"172\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,190.58823529411765 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"147\" y2=\"17\" />\n",
       "  <line x1=\"45\" y1=\"35\" x2=\"165\" y2=\"35\" />\n",
       "  <line x1=\"62\" y1=\"52\" x2=\"182\" y2=\"52\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"40\" y1=\"0\" x2=\"110\" y2=\"70\" />\n",
       "  <line x1=\"70\" y1=\"0\" x2=\"140\" y2=\"70\" />\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"170\" y2=\"70\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 200.58823529411765,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"100\" x2=\"200\" y2=\"100\" />\n",
       "  <line x1=\"80\" y1=\"130\" x2=\"200\" y2=\"130\" />\n",
       "  <line x1=\"80\" y1=\"160\" x2=\"200\" y2=\"160\" />\n",
       "  <line x1=\"80\" y1=\"190\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"110\" y1=\"70\" x2=\"110\" y2=\"190\" />\n",
       "  <line x1=\"140\" y1=\"70\" x2=\"140\" y2=\"190\" />\n",
       "  <line x1=\"170\" y1=\"70\" x2=\"170\" y2=\"190\" />\n",
       "  <line x1=\"200\" y1=\"70\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 200.58823529411765,70.58823529411765 200.58823529411765,190.58823529411765 80.58823529411765,190.58823529411765\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"140.588235\" y=\"210.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000</text>\n",
       "  <text x=\"220.588235\" y=\"130.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,220.588235,130.588235)\">1000</text>\n",
       "  <text x=\"35.294118\" y=\"175.294118\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,175.294118)\">1000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(1000, 1000, 1000), dtype=float64, chunksize=(250, 250, 250), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# da lets us scale out to the cluster more efficiently than npy\n",
    "import dask.array as da\n",
    "x = da.random.random((1000, 1000, 1000))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1528269 , 0.73128592, 0.54163584, ..., 0.86250423,\n",
       "         0.00938134, 0.99052283],\n",
       "        [0.98192313, 0.18536231, 0.94974781, ..., 0.66356631,\n",
       "         0.50824672, 0.27509965],\n",
       "        [0.55184687, 0.91434221, 0.1738722 , ..., 0.11187265,\n",
       "         0.27047543, 0.21469505],\n",
       "        ...,\n",
       "        [0.89691145, 0.58460763, 0.13615294, ..., 0.30249869,\n",
       "         0.27796905, 0.43230158],\n",
       "        [0.21621162, 0.26594022, 0.64527125, ..., 0.52795095,\n",
       "         0.00117765, 0.41975114],\n",
       "        [0.59384762, 0.09135375, 0.16423744, ..., 0.59283497,\n",
       "         0.22632899, 0.20654085]],\n",
       "\n",
       "       [[0.16640887, 0.62154262, 0.43467535, ..., 0.01744579,\n",
       "         0.10629485, 0.01673153],\n",
       "        [0.66014438, 0.87871253, 0.01207695, ..., 0.91857453,\n",
       "         0.45560393, 0.86222286],\n",
       "        [0.377713  , 0.89378863, 0.00605999, ..., 0.22809737,\n",
       "         0.26318572, 0.53233163],\n",
       "        ...,\n",
       "        [0.62743982, 0.98589463, 0.86501689, ..., 0.92374094,\n",
       "         0.05474441, 0.98064099],\n",
       "        [0.05727252, 0.31657853, 0.64157128, ..., 0.00366745,\n",
       "         0.71159477, 0.20864437],\n",
       "        [0.42836092, 0.48544514, 0.2306192 , ..., 0.61460248,\n",
       "         0.72494411, 0.32612058]],\n",
       "\n",
       "       [[0.42274484, 0.03976887, 0.84937741, ..., 0.12329775,\n",
       "         0.99289639, 0.67631602],\n",
       "        [0.45525188, 0.20218956, 0.096188  , ..., 0.43000289,\n",
       "         0.63666571, 0.70253465],\n",
       "        [0.86799886, 0.25219575, 0.22144157, ..., 0.3156697 ,\n",
       "         0.86266102, 0.44211379],\n",
       "        ...,\n",
       "        [0.68531877, 0.79828866, 0.36860277, ..., 0.23102939,\n",
       "         0.66900437, 0.92962347],\n",
       "        [0.0649906 , 0.16171366, 0.41357052, ..., 0.71982537,\n",
       "         0.88016538, 0.74004424],\n",
       "        [0.40509674, 0.74439879, 0.77911191, ..., 0.22500785,\n",
       "         0.65741738, 0.18656288]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.89536662, 0.05383356, 0.35715006, ..., 0.58803496,\n",
       "         0.50731962, 0.07811823],\n",
       "        [0.9363673 , 0.47461579, 0.52188528, ..., 0.8545234 ,\n",
       "         0.58902289, 0.4977388 ],\n",
       "        [0.99896818, 0.670751  , 0.68429657, ..., 0.61768013,\n",
       "         0.67849578, 0.46813267],\n",
       "        ...,\n",
       "        [0.78242804, 0.56765431, 0.38645205, ..., 0.3704036 ,\n",
       "         0.23468871, 0.33502716],\n",
       "        [0.32049205, 0.52664092, 0.59516042, ..., 0.74734606,\n",
       "         0.55146168, 0.88614552],\n",
       "        [0.45120197, 0.53317755, 0.51401268, ..., 0.7545737 ,\n",
       "         0.93622804, 0.18081465]],\n",
       "\n",
       "       [[0.54677082, 0.86756564, 0.2257234 , ..., 0.88323045,\n",
       "         0.06739291, 0.6396963 ],\n",
       "        [0.51166698, 0.07674342, 0.84323795, ..., 0.38433096,\n",
       "         0.30203964, 0.89170503],\n",
       "        [0.27607342, 0.05326248, 0.17954794, ..., 0.57168061,\n",
       "         0.97783532, 0.90385184],\n",
       "        ...,\n",
       "        [0.55708691, 0.17134441, 0.81203852, ..., 0.15173479,\n",
       "         0.22778309, 0.49963564],\n",
       "        [0.84753333, 0.04019536, 0.80529665, ..., 0.93608434,\n",
       "         0.13423868, 0.69904897],\n",
       "        [0.13200081, 0.3254607 , 0.2119503 , ..., 0.89185501,\n",
       "         0.39221092, 0.90210633]],\n",
       "\n",
       "       [[0.33046181, 0.24163296, 0.84594078, ..., 0.61695582,\n",
       "         0.69825289, 0.07517678],\n",
       "        [0.11084394, 0.92755774, 0.16569656, ..., 0.73368215,\n",
       "         0.56418543, 0.67886374],\n",
       "        [0.93474129, 0.50406569, 0.59477837, ..., 0.24616139,\n",
       "         0.84147487, 0.29010574],\n",
       "        ...,\n",
       "        [0.72192695, 0.4022427 , 0.13656509, ..., 0.91351827,\n",
       "         0.58635101, 0.34595024],\n",
       "        [0.32652903, 0.98877368, 0.79425668, ..., 0.49696944,\n",
       "         0.77114814, 0.05916668],\n",
       "        [0.42089442, 0.69380213, 0.38383036, ..., 0.81981825,\n",
       "         0.92351757, 0.1128982 ]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check squeue while this is running to see the jobs dynamically spinning up\n",
    "x.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.34572215, 0.43556403, 0.12558177, ..., 0.49003415,\n",
       "         0.85630438, 0.79450724],\n",
       "        [0.66733073, 0.025424  , 0.02184396, ..., 0.21553809,\n",
       "         0.52054652, 0.28891133],\n",
       "        [0.3733833 , 0.45080879, 0.92277408, ..., 0.81119711,\n",
       "         0.08831033, 0.99256316],\n",
       "        ...,\n",
       "        [0.9953759 , 0.00840521, 0.85993305, ..., 0.27023196,\n",
       "         0.48049836, 0.7744583 ],\n",
       "        [0.81221035, 0.74607981, 0.19407742, ..., 0.73366886,\n",
       "         0.6999948 , 0.41679576],\n",
       "        [0.86969061, 0.84317931, 0.62250744, ..., 0.85697147,\n",
       "         0.82231557, 0.79759314]],\n",
       "\n",
       "       [[0.76864969, 0.76818799, 0.7999283 , ..., 0.81951779,\n",
       "         0.03667452, 0.47616253],\n",
       "        [0.94602241, 0.19928793, 0.15302713, ..., 0.67441548,\n",
       "         0.83188983, 0.88484947],\n",
       "        [0.4180656 , 0.85396532, 0.43575906, ..., 0.61590593,\n",
       "         0.31649307, 0.85529874],\n",
       "        ...,\n",
       "        [0.64447301, 0.1578159 , 0.26899086, ..., 0.72044637,\n",
       "         0.72996813, 0.52013984],\n",
       "        [0.53113341, 0.59534999, 0.59456224, ..., 0.1862711 ,\n",
       "         0.26261092, 0.67539664],\n",
       "        [0.40047631, 0.0114829 , 0.01576228, ..., 0.97160905,\n",
       "         0.18544728, 0.02456203]],\n",
       "\n",
       "       [[0.22666211, 0.93732908, 0.01738147, ..., 0.08980268,\n",
       "         0.32335453, 0.80829732],\n",
       "        [0.70448617, 0.12109105, 0.56132397, ..., 0.74058537,\n",
       "         0.53524069, 0.31686656],\n",
       "        [0.64718187, 0.36471226, 0.33692348, ..., 0.03236407,\n",
       "         0.52016565, 0.946934  ],\n",
       "        ...,\n",
       "        [0.74789299, 0.58059438, 0.83802584, ..., 0.52450548,\n",
       "         0.52636551, 0.02694117],\n",
       "        [0.41446294, 0.36895781, 0.97152923, ..., 0.59970711,\n",
       "         0.30498834, 0.28916366],\n",
       "        [0.46528894, 0.36413066, 0.85593033, ..., 0.54725561,\n",
       "         0.34146475, 0.38198366]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.17070155, 0.31991279, 0.22649686, ..., 0.06627674,\n",
       "         0.27500337, 0.47473315],\n",
       "        [0.51976233, 0.48707128, 0.97792636, ..., 0.5813465 ,\n",
       "         0.20683037, 0.98225883],\n",
       "        [0.00363582, 0.09909345, 0.31904514, ..., 0.69324978,\n",
       "         0.81240886, 0.25195061],\n",
       "        ...,\n",
       "        [0.40180588, 0.8382762 , 0.69265434, ..., 0.91454279,\n",
       "         0.06751838, 0.18854913],\n",
       "        [0.11004932, 0.57054399, 0.33294745, ..., 0.96475519,\n",
       "         0.92460396, 0.35035251],\n",
       "        [0.06418527, 0.49291972, 0.79140098, ..., 0.95311906,\n",
       "         0.88660986, 0.5729765 ]],\n",
       "\n",
       "       [[0.06561934, 0.4285561 , 0.20543143, ..., 0.40332799,\n",
       "         0.38965104, 0.30401372],\n",
       "        [0.21184903, 0.0547208 , 0.80405659, ..., 0.13948968,\n",
       "         0.18990544, 0.77050884],\n",
       "        [0.99925687, 0.58672602, 0.57402467, ..., 0.63489949,\n",
       "         0.26099766, 0.19537877],\n",
       "        ...,\n",
       "        [0.49807903, 0.40033258, 0.90259669, ..., 0.36924087,\n",
       "         0.09319128, 0.94430768],\n",
       "        [0.50444094, 0.4784031 , 0.7975609 , ..., 0.46626259,\n",
       "         0.69476912, 0.76323472],\n",
       "        [0.28527786, 0.1471754 , 0.1156093 , ..., 0.09427526,\n",
       "         0.90989677, 0.41325946]],\n",
       "\n",
       "       [[0.96511543, 0.2057444 , 0.92433476, ..., 0.75634927,\n",
       "         0.68593837, 0.3377386 ],\n",
       "        [0.34717128, 0.75662708, 0.27391829, ..., 0.279457  ,\n",
       "         0.97522362, 0.4897602 ],\n",
       "        [0.40291634, 0.7912993 , 0.32439136, ..., 0.75022568,\n",
       "         0.78833212, 0.05815434],\n",
       "        ...,\n",
       "        [0.78320635, 0.43481809, 0.5270015 , ..., 0.12190118,\n",
       "         0.94486151, 0.28040902],\n",
       "        [0.1037545 , 0.80533777, 0.17637039, ..., 0.5853567 ,\n",
       "         0.75420975, 0.63475475],\n",
       "        [0.87217214, 0.67952424, 0.29462212, ..., 0.56080859,\n",
       "         0.26284842, 0.95748728]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also accelerate dask arrays with GPUs using cupy\n",
    "# There are similar analogues for the rest of RAPIDs\n",
    "dask.config.set({\"array.backend\": \"cupy\"})\n",
    "y = da.random.random((1000, 1000, 1000))\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the cluster\n",
    "client.shutdown()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how Dask works with a typical PyTorch workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch to a localcluster as its easier for interactive development. This will make all code execute locally allowing you to view print statements and debug errors normally rather than dealing with remote code execusion before we're ready.\n",
    "\n",
    "Dask prefers to control all processes so that it can manage them more gracefully if they fail, but we need to give PyTorch the control to use multiprocessing as needed. To do this set `proccesses=False` to allow for multiprocessing inside Dask jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a new local cluster and client\n",
    "cluster = LocalCluster(processes=False)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use CIFAR as our case study for this example.\n",
    "Content adapted from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Define dataset and dataloader\n",
    "batch_size = 1024\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "validset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# Note that we need to set the multiprocessing context so that PyTorch doesn't get\n",
    "# PyTorch likes to use 'forking' while Dask uses 'spawn'\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=16, multiprocessing_context=mp.get_context(\"fork\"))\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=16, multiprocessing_context=mp.get_context(\"fork\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple conv net\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 64, 4 * 64)\n",
    "        self.fc2 = nn.Linear(4 * 64, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train one epoch\n",
    "def train(loader, path=\"./model\", load=False, test=False, error=False):\n",
    "    # Initialise model, optimizer and device\n",
    "    model = Net()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load state from disk so that we can split up the job\n",
    "    if load: \n",
    "        state = torch.load(path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model.to(device)\n",
    "        optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    else:\n",
    "        model.to(device)\n",
    "    \n",
    "    # A typical PyTorch training loop\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        # put the inputs on the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        # Force an error\n",
    "        if error:\n",
    "            assert 0 == 1\n",
    "        \n",
    "        # Stop after one batch when testing        \n",
    "        if test: \n",
    "            print(\"When running in a local cluster you can see print statements\")\n",
    "            break\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    torch.save({\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    return running_loss / len(loader) if not test else loss.detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid one epoch\n",
    "def valid(loader, path=\"./model\"):\n",
    "    # Initialise model, optimizer and device\n",
    "    model = Net()\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load state from disk so that we can split up the job\n",
    "    state = torch.load(path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # A typical PyTorch validation loop\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            # put the inputs on the device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.detach().item()\n",
    "            \n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "\n",
    "    return running_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When running in a local cluster you can see print statements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.303812265396118"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our code locally first\n",
    "client.submit(train, trainloader, test=True).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the cluster\n",
    "client.shutdown()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask usually uses a 'nanny' that monitors any worker processes and gracefully restarts them if they fail or are killed while performing computations. The nanny is not compatable with daemonic processes - that is dask workers cannot perform multiprocessing while it's being used. We therefore need to set `nanny=False` to turn off the nanny to allow for multiprocessing inside Dask jobs for the cluster to work with PyTorch. (Just like when we `processes=False` for the local cluster.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass in extra SLURM requirements in job_extra_directives to request a GPU for our jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch over to remote execusion\n",
    "cluster = SLURMCluster(\n",
    "    memory=\"64g\", processes=1, cores=8, job_extra_directives=[\"--gres=gpu:1\"], nanny=False\n",
    ")\n",
    "\n",
    "cluster.scale(1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.306060314178467"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since this code is executing remotely we won't see our print statements\n",
    "client.submit(train, trainloader, test=True).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Dask will raise any errors that the process triggers locally, even when executing remotely\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m client\u001b[39m.\u001b[39;49msubmit(train, trainloader, error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/userdata/mhar0048/miniconda/conda/envs/dask/lib/python3.10/site-packages/distributed/client.py:280\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    279\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m result\n\u001b[0;32m--> 280\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    281\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcancelled\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    282\u001b[0m     \u001b[39mraise\u001b[39;00m result\n",
      "\u001b[1;32m/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb Cell 28\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Force an error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Stop after one batch when testing        \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c6552505f6d68617230303438227d/home/mhar0048/mlerp-documentation/dask-pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m test: \n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dask will raise any errors that the process triggers locally, even when executing remotely\n",
    "client.submit(train, trainloader, error=True).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53678ee184d041549effae380371d211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 23:59:29,801 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss:  2.254, valid_loss:  2.102, accuracy:  0.235\n",
      "epoch: 1, train_loss:  2.030, valid_loss:  1.971, accuracy:  0.280\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "epochs = 2\n",
    "\n",
    "with tqdm(total=(epochs)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = client.submit(train, trainloader, load=epochs).result()\n",
    "        valid_loss, accuracy = client.submit(valid, validloader).result()\n",
    "        pbar.update()\n",
    "        pbar.set_postfix(loss=train_loss)\n",
    "        print(\n",
    "            f\"epoch: {epoch}, train_loss: {train_loss : .3f}, valid_loss: {valid_loss : .3f}, accuracy: {accuracy : .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the cluster\n",
    "client.shutdown()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db096b8404a4f1f3e1df0cc89f001e138448327417ef835d10f5a76aa612f160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
